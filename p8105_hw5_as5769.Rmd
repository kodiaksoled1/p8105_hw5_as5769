---
title: "Homework 5"
author: "Kodiak Soled"
date: "11/2/2019"
output: github_document
always_allow_html: yes
---

```{r setting up document, include = FALSE}
library(tidyverse)
library(patchwork)
library(viridis)
library(kableExtra)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d

scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

#### Read in Data

First, I read in the missing data. 

```{r loading in missing dataset}
set.seed(10)

iris_with_missing = 
  iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

#### Create a Function to Address Missing Data

In order to fill in the missing data, I first needed to write a `function` that:

* Took a vector as an argument
* `Replace`d missing values:
    * of numeric variables with the mean of non-missing values
    * of character variables with `"virginica"`
* Returned the resulting vector

```{r write a function to replace missing values}
tidy_iris = function(x) {
  
  if (!is.numeric(x) & !is.character(x)) {
    stop("Argument x should be numeric or character")
  } else if (is.character(x)) {
    x = replace(x, is.na(x) == TRUE, "virginica")
  } else if (is.numeric(x)) {
    mean_x = mean(x, na.rm = TRUE)
    x = replace(x, is.na(x) == TRUE, mean_x)
  }
  
}
```

#### Create a Map Statement

Then, I applied this function to the `iris_with_missing` dataset using a `map` statement and `bind_rows` in order to combine the 5 datasets into a single one:

```{r write a map statement, warning = FALSE}
output = 
  map(iris_with_missing, tidy_iris) %>%
  bind_rows()
```

#### Table of New Iris Data

Here is a reader-friendly table the first 30 observations of the replaced iris dataset:

```{r resulting table}
head(output, n = 30) %>%
  janitor::clean_names() %>%
  knitr::kable(digits = 1, caption = "Iris Dataset (First 30 Observations)") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", font_size = 12))
```

## Problem 2

#### Load in Data files

In order to create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time, I first loaded in the 20 seperate datafiles using `list.files` (created a dataframe with the file names):

```{r}
study_data_2 = 
  list.files(path = "./data_hw5", full.names = FALSE) %>%
  tibble::enframe(name = NULL)
study_data_2
```

#### Create Tidy Dataframe

Then, I iterated over the file names and read in the data (`read_csv`) for each of the 20 subjects (from 20 strings to 1 string using `str_c`) using `purrr::map` (and saving the result as a new variable in the dataframe). I then `unnest`ed the variable "data" so I could see the measurements for each subject across the eight weeks. I then tidied the dataset so that there were `seperate` variables for study group (control vs. experimental) and subject id and removed the ".csv" in the name using `mutate` and `str_replace`. Finally, I put the dataframe into a reader-friendly table using `knitr::kable` and made sure all the measurements were rounded to 2 decimal places using `digits = 2`.

```{r write using map, message = FALSE}
df_study_data_2 = 
  study_data_2 %>%
  mutate(
    data = map(value, ~read_csv(str_c("./data_hw5/", .x)))
  ) %>%
  unnest(cols = data) %>%
  separate(value, into = c("arm", "subject_id"), sep = "_") %>%
  mutate(subject_id = str_replace(subject_id, ".csv", ""))
df_study_data_2 %>%
  knitr::kable(digits = 2, caption = "Tidy Study Dataframe") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", font_size = 12))

```

#### Make Spaghetti Plots

Next, I used `pivot_longer` to tidy the data in a way that allowed me to make a spaghetti plot which showed observations on each subject over time:

```{r}
df = 
  df_study_data_2 %>%
  pivot_longer(
    cols = starts_with("week_"),
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation"
    ) %>%
 mutate(
   arm = recode(arm,
                `con` = "Control",
                `exp` = "Experimental"
                )
   ) %>%
  rename(Group = arm)
```

My first graph I made allows you to see the two study groups on the same graph. We can see the differences between the two study arms by the two colors: 

```{r}
ggplot(df, aes(x = week, y = observation, group = subject_id, color = Group)) + 
  geom_path() +
  labs(
    title = "Observation of Each Study Subject over Eight Weeks By Study Group",
    x = "Week",
    y = "Observation",
    caption = "Data from HW 5 Problem 2 Zip File")
```

My second graph stratified the two study groups using `facet_grid`. In this graph we can see each of the 20 study participants as well as the differences between the two study groups:

```{r}
ggplot(df, aes(x = week, y = observation, group = subject_id, color = subject_id)) + 
  geom_line() + 
  facet_grid(~Group) +
  labs(
    title = "Observation of Each Study Subject over Eight Weeks By Study Group",
    x = "Week",
    y = "Observation",
    caption = "Data from HW 5 Problem 2 Zip File")
```

#### Description of Differences Between Groups

The control group seems to maintain the same measurements across the eight weeks whereas the experimental group seems to significantly increase their measurements across the eight weeks. It would appear that the independent variable in the study is making an positive impact on whatever dependent varaible it is trying to increase.

## Problem 3 

#### Make a Function

First, I made a function which fixed the following design elements:
  * n = 30
  * xi1 as draws from a standard Normal distribution
  * β0 = 2
  * σ2 = 50
and set β1 = 0. 

I then put the _lm_ for yi = β0 + β1xi1 + ϵi with ϵi∼N[0,σ2] inside the function and generated the estimate and p-value using the `broom::tidy` function
  
For each dataset, I saved (`select`ed) the estimate and p-value of β̂1 by `filter`ing for "x:

```{r}
set.seed(1)

sim_regression = function(beta1 = 0) {

  sim_data = tibble(
    x = rnorm(30, mean = 1, sd = 1),
    y = 2 + beta1 * x + rnorm(30, 0, sqrt(50))
  )

  ls_fit = lm(y ~ x, data = sim_data)
  
  broom::tidy(ls_fit) %>%
    filter(term == "x") %>%
    select(estimate, p.value)
  
}
```

#### Generate 10,0000 Datasets for β1 = 0

I then generated 10,000 datasets of β1 = 0 using `rerun` on my "sim_regression" function and used `bind_rows` to create one massive dataset from the list of 10,000 datasets:

```{r writing a map statement}
output = 
  rerun(10000, sim_regression(beta1 = 0)) %>%
  bind_rows()
```

The first 10 rows of this simulated dataset of β1 = 0 can be seen here:

```{r}
head(output, n = 10) %>%
  janitor::clean_names() %>%
  knitr::kable(digits = 3, caption = "First 10 Rows of Simulation Regression for β1 = 0") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", font_size = 12))
```